{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "understood-mounting",
   "metadata": {},
   "source": [
    "# Оценка функции времени работы для BattleField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-robin",
   "metadata": {},
   "source": [
    "_Дано_: количество завершенных матчей $things$, количество потоков $jobs$.\n",
    "\n",
    "_Требуется_: оценить матожидание общего времени работы при условии, что матожидание времени одного матча $\\textbf{E} \\xi$ равно $1.0$. Распределение $\\xi$ неизвестно, поэтому для простоты предполагаем, что $\\xi\\sim \\mathcal{N}(1.0, 0.15)$.\n",
    "\n",
    "Для оценки будем использовать функцию $f(jobs, things) = \\frac{jobs}{things} + G(jobs, things)$, где $G(jobs, things)$ &mdash; некоторая модель, которую мы ниже и будем обучать. Я люблю линейные модели, поэтому модель будет линейной регрессией с наинжиниренными фичами.\n",
    "\n",
    "Оценивать качество будем так. Пусть $y_1, y_2, \\dots, y_n$ &mdash; истинные значения матожидания (полученные с помощью метода Монте-Карло), а $y'_1, y'_2, \\dots, y'_n$ &mdash; наши оценки. Тогда для оценки моделей рассмотрим скоры $s_{avg}$ и $s_{max}$, которые вычисляются по формулам:\n",
    "$$s_{avg} = \\sqrt{\\frac{\\sum_\\limits{i=1}^n \\left(\\frac{y_i - y'_i}{y_i}\\right)^2 }n}$$\n",
    "$$s_{max} = \\max\\limits_{i=1\\dots n}{\\left| \\frac{y_i - y'_i}{y_i} \\right|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-climb",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-restaurant",
   "metadata": {},
   "source": [
    "Сначала напишем функцию для симуляции процесса с помощью метода Монте-Карло:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "buried-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def simulate(jobs, things, sigma=0.15, iters=10_000):\n",
    "    sum_time = 0.0\n",
    "\n",
    "    for i in range(iters):\n",
    "        heap = []\n",
    "        time = 0.0\n",
    "        for _ in range(things):\n",
    "            if len(heap) == jobs:\n",
    "                time = heapq.heappop(heap)\n",
    "            heapq.heappush(heap, time + max(0.0, random.gauss(1.0, sigma)))\n",
    "        time = max(heap + [time])\n",
    "        sum_time += time\n",
    "\n",
    "    return sum_time / iters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-phone",
   "metadata": {},
   "source": [
    "Сгенерируем датасет. Будем генерировать его честно, чтобы строчки с маленькими значениями $jobs$ и $things$ тоже встречались достаточно большое количество раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "differential-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def expand(my_list, need_size):\n",
    "    if len(my_list) >= need_size:\n",
    "        return copy.copy(my_list)\n",
    "    new_list = copy.copy(my_list)\n",
    "    for i in range(len(my_list), need_size):\n",
    "        new_list.append(random.choice(my_list))\n",
    "    return new_list\n",
    "    \n",
    "dataset = []\n",
    "for jobs in range(1, 33):\n",
    "    small = random.sample(range(1, 4 * jobs + 1), k=min(4*jobs, 20))\n",
    "    small = expand(small, 20)\n",
    "    large = random.sample(range(4 * jobs + 1, 12 * jobs + 1), k=min(4*jobs, 15))\n",
    "    large = expand(large, 15)\n",
    "    dataset += [[jobs, things] for things in small + large]\n",
    "\n",
    "X = np.array(dataset).astype(dtype=np.float64)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-duplicate",
   "metadata": {},
   "source": [
    "Сгенерируем ответы (осторожно, это достаточно долго!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "y = [simulate(int(ln[0]), int(ln[1])) - ln[1] / ln[0] for ln in tqdm(X)]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-palmer",
   "metadata": {},
   "source": [
    "Сохраним датасет, чтобы не потерять его. А то он довольно долго генерируется :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "adapted-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'jobs,things,y'\n",
    "dataset = np.c_[X, np.array(y).reshape(-1, 1)]\n",
    "np.savetxt('dataset1.csv', dataset, fmt='%.14f', delimiter=',', header=header, comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-retrieval",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-filename",
   "metadata": {},
   "source": [
    "Загружаем датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "threaded-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('dataset0.csv').values\n",
    "X = dataset[:, :-1]\n",
    "y = np.array(dataset[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-dryer",
   "metadata": {},
   "source": [
    "Расширим датасет дополнительными признаками: $1$, $\\log things$, $\\frac 1{jobs}$, $\\frac{\\log things}{jobs}$, $\\frac 1{jobs^2}$, $\\frac {\\log things}{jobs^2}$, $\\frac {things}{jobs^2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "confident-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = X[:, 0]\n",
    "things = X[:, 1]\n",
    "X = np.c_[\n",
    "    jobs,\n",
    "    things,\n",
    "    np.array([1. for _ in X]),\n",
    "    np.log(things),\n",
    "    1. / jobs,\n",
    "    np.log(things) / jobs,\n",
    "    1. / (jobs ** 2),\n",
    "    np.log(things) / (jobs ** 2),\n",
    "    things / (jobs ** 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-reconstruction",
   "metadata": {},
   "source": [
    "Делим наш датасет на `train` и `test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "technical-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-temperature",
   "metadata": {},
   "source": [
    "Вводим метрики (точные формулы см. выше):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "medieval-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(X, y_pred, y_real):\n",
    "    y1_pred = y_pred + X[:, 1] / X[:, 0]\n",
    "    y1_real = y_real + X[:, 1] / X[:, 0]\n",
    "    return np.sqrt(np.mean((y1_real / y1_pred - 1.) ** 2))\n",
    "\n",
    "def estimate_max(X, y_pred, y_real):\n",
    "    y1_pred = y_pred + X[:, 1] / X[:, 0]\n",
    "    y1_real = y_real + X[:, 1] / X[:, 0]\n",
    "    return np.max(np.abs(y1_real / y1_pred - 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-sauce",
   "metadata": {},
   "source": [
    "Генерим константные предсказания, чтобы понять baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "studied-effort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.10398750297737731\n",
      "Max: 0.5605603872498814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred = dummy.predict(X_test)\n",
    "print('Average:', estimate(X_test, y_pred, y_test))\n",
    "print('Max:', estimate_max(X_test, y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-utilization",
   "metadata": {},
   "source": [
    "Обучаем линейную регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "close-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.05484311003621325\n",
      "Max: 0.23374952098685364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "model = Lasso(alpha=1e-5, max_iter=10000, fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Average:', estimate(X_test, y_pred, y_test))\n",
    "print('Max:', estimate_max(X_test, y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-deficit",
   "metadata": {},
   "source": [
    "А если на всех данных обучить? (Скоры ниже получены на той же выборке, на которой обучалась модель, поэтому могут быть необъективны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "polyphonic-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.05800443672073826\n",
      "Max: 0.2402331194843712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "model = clone(model)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "print('Average:', estimate(X, y_pred, y))\n",
    "print('Max:', estimate_max(X, y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-spencer",
   "metadata": {},
   "source": [
    "Взглянем на коэффициенты, чтобы применить результат обучения в самой программе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "weighted-glucose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.77918644e-03,  8.64226651e-04,  9.46858137e-01, -1.07427060e-01,\n",
       "       -1.38769432e+00,  2.61388592e-02,  4.51703118e-01, -1.17767833e-01,\n",
       "        4.56262770e-02])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
